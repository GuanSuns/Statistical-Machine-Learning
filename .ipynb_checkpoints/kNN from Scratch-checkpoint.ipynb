{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kNN from Scratch\n",
    "- Implement kNN from scratch\n",
    "- Use MNIST handwriting dataset for evaluation\n",
    "- Use the kNN model in sklearn for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.utils.random import sample_without_replacement\n",
    "import random\n",
    "import math\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Dataset\n",
    "- Link: http://yann.lecun.com/exdb/mnist/\n",
    "- The data reader is based on: https://colab.research.google.com/github/chokkan/deeplearningclass/blob/master/mnist.ipynb#scrollTo=TStlGwaUaZKC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training image shape:  (60000, 28, 28)\n",
      "training image vectors shape:  (60000, 784)\n",
      "training label shape:  (60000,)\n",
      "test image shape:  (10000, 28, 28)\n",
      "test image vectors shape:  (10000, 784)\n",
      "test label shape:  (10000,)\n",
      "\n",
      "After sampling: \n",
      "training image shape:  (10000, 28, 28)\n",
      "training image vectors shape:  (10000, 784)\n",
      "training label shape:  (10000,)\n",
      "test image shape:  (1000, 28, 28)\n",
      "test image vectors shape:  (1000, 784)\n",
      "test label shape:  (1000,)\n"
     ]
    }
   ],
   "source": [
    "def read_mnist_dataset(dir_minst):\n",
    "    training_img_file = os.path.join(dir_minst, 'train-images-idx3-ubyte')\n",
    "    training_label_file = os.path.join(dir_minst, 'train-labels-idx1-ubyte')\n",
    "    \n",
    "    test_img_file = os.path.join(dir_minst, 't10k-images-idx3-ubyte')\n",
    "    test_label_file = os.path.join(dir_minst, 't10k-labels-idx1-ubyte')\n",
    "    \n",
    "    # read the training set\n",
    "    training_label = None\n",
    "    with open(training_label_file, 'rb') as f:\n",
    "        magic, num = struct.unpack(\">II\", f.read(8))\n",
    "        training_label = np.fromfile(f, dtype=np.int8)\n",
    "    \n",
    "    training_img = None\n",
    "    with open(training_img_file, 'rb') as f:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\", f.read(16))\n",
    "        training_img = np.fromfile(f, dtype=np.uint8).reshape(len(training_label), rows, cols)\n",
    "        \n",
    "    # read the testing set\n",
    "    test_label = None\n",
    "    with open(test_label_file, 'rb') as f:\n",
    "        magic, num = struct.unpack(\">II\", f.read(8))\n",
    "        test_label = np.fromfile(f, dtype=np.int8)\n",
    "    \n",
    "    test_img = None\n",
    "    with open(test_img_file, 'rb') as f:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\", f.read(16))\n",
    "        test_img = np.fromfile(f, dtype=np.uint8).reshape(len(test_label), rows, cols)\n",
    "        \n",
    "    return training_img.astype(np.float64), training_label, test_img.astype(np.float64), test_label\n",
    "\n",
    "data_dir = 'dataset/MNIST'\n",
    "training_img, training_label, test_img, test_label = read_mnist_dataset(data_dir)\n",
    "training_img_vectors = np.reshape(training_img, (training_img.shape[0], -1))\n",
    "test_img_vectors = np.reshape(test_img, (test_img.shape[0], -1))\n",
    "\n",
    "print('training image shape: ', training_img.shape)\n",
    "print('training image vectors shape: ', training_img_vectors.shape)\n",
    "print('training label shape: ', training_label.shape)\n",
    "print('test image shape: ', test_img.shape)\n",
    "print('test image vectors shape: ', test_img_vectors.shape)\n",
    "print('test label shape: ', test_label.shape)\n",
    "\n",
    "# the dataset is too big, so we use a subset of it\n",
    "print('\\nAfter sampling: ')\n",
    "traning_subset_idx = sample_without_replacement(n_population=training_img_vectors.shape[0], n_samples=10000)\n",
    "training_img_vectors = training_img_vectors[traning_subset_idx]\n",
    "training_label = training_label[traning_subset_idx]\n",
    "training_img = training_img[traning_subset_idx]\n",
    "\n",
    "test_subset_idx = sample_without_replacement(n_population=test_img_vectors.shape[0], n_samples=1000)\n",
    "test_img_vectors = test_img_vectors[test_subset_idx]\n",
    "test_label = test_label[test_subset_idx]\n",
    "test_img = test_img[test_subset_idx]\n",
    "\n",
    "print('training image shape: ', training_img.shape)\n",
    "print('training image vectors shape: ', training_img_vectors.shape)\n",
    "print('training label shape: ', training_label.shape)\n",
    "print('test image shape: ', test_img.shape)\n",
    "print('test image vectors shape: ', test_img_vectors.shape)\n",
    "print('test label shape: ', test_label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the Data (Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  2\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAOAklEQVR4nO3da6xV9ZnH8d9PB5VYNTJEg5RovSTOMMlYJWYS7yKNg1Hsi47yYsR4OSUpkeq8GK0mNTEaYqZVX2gNjVJmItZ6aUAzCRqsOr5pAOOFyxSQMC2XgMZoLRir8syLszBHPOu/j/u2Nuf5fpKTvfd6ztrryT78WGvv/1r774gQgPHvsKYbANAfhB1IgrADSRB2IAnCDiTxN/3cmG0++gd6LCI82vKO9uy2L7f9B9tbbN/eyXMB6C23O85u+3BJmyTNkrRd0mpJcyNiQ2Ed9uxAj/Viz36upC0RsTUi/irp15LmdPB8AHqok7BPlfSnEY+3V8u+wvaQ7TW213SwLQAd6uQDutEOFb52mB4RiyUtljiMB5rUyZ59u6RpIx5/W9LOztoB0CudhH21pDNsf8f2EZKulbSiO20B6La2D+Mj4nPbCyStlHS4pMcjYn3XOgPQVW0PvbW1Md6zAz3Xk5NqABw6CDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1Ioq9TNuPQc/755xfrEydOLNbvvPPO2toFF1zQVk8H3HfffcX6okWLamt79+7taNuHIvbsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEs7iOA9OnT6+tzZo1q7juVVddVaxfdNFFxXo///0czB51stIvXXrppbW1V199tdvtDIy6WVw7OqnG9jZJH0v6QtLnETGjk+cD0DvdOIPukoh4vwvPA6CHeM8OJNFp2EPSi7bX2h4a7RdsD9leY3tNh9sC0IFOD+PPi4idtk+Q9JLt/42I10b+QkQslrRY4gM6oEkd7dkjYmd1u0fSbyWd242mAHRf22G3fbTtYw7cl/Q9Seu61RiA7mp7nN32qRrem0vDbweWRcS9LdbhML4N119/fbF+//3319YmTZrU0bZbjWUP8jj72rVra2uXXHJJcd1D+Xr3ro+zR8RWSf/YdkcA+oqhNyAJwg4kQdiBJAg7kARhB5LgEtcBMG3atGJ99erVxfrkyZO72c5XtBreeuaZZ4r1p59+upvtfMVTTz1VrJf+bZ9zzjnFdd966622ehoEdUNv7NmBJAg7kARhB5Ig7EAShB1IgrADSRB2IAmmbB4AN998c7Hey3H0VpYvX16s33DDDcX6oF4qOmfOnGL9UB5nr8OeHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSYJx9ANx1113FeiffObBv375i/YUXXijW586d2/a2e63Vtfa9WvdQxZ4dSIKwA0kQdiAJwg4kQdiBJAg7kARhB5JgnH0ArFy5slg/9dRTi/UPP/ywtjY0NFRcd5Cv2z799NOL9VbnH5TqTU413ZSWe3bbj9veY3vdiGWTbL9ke3N1e3xv2wTQqbEcxv9K0uUHLbtd0qqIOEPSquoxgAHWMuwR8ZqkDw5aPEfS0ur+UklXd7kvAF3W7nv2EyNilyRFxC7bJ9T9ou0hSeU3jgB6rucf0EXEYkmLJSZ2BJrU7tDbbttTJKm63dO9lgD0QrthXyFpXnV/nqTy9w0DaFzLw3jbT0q6WNJk29sl/VTSIkm/sX2jpD9K+kEvmxzvrrzyymL9qKOOKtZLY8aD+r3tY9Hqu91b+fTTT2trra7zH49ahj0i6r69YGaXewHQQ5wuCyRB2IEkCDuQBGEHkiDsQBLu56V+nEGHkaZPn16sv/7668X6scceW6zfdNNNtbUlS5YU1z2URcSo35PNnh1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkuCrpNFTEydOrK098MADxXWPOeaYjra9devWjtYfb9izA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASjLOjpxYtWlRbmzmzsy8o3rBhQ7G+ZcuWjp5/vGHPDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJ8L3xA+C4444r1m+99dZiff369bW19957r7juK6+8Uqy30uqa9Pnz59fWJkyY0NG2Tz755GJ9x44dHT3/oart7423/bjtPbbXjVh2t+0dtt+sfmZ3s1kA3TeWw/hfSbp8lOUPRMRZ1c9/d7ctAN3WMuwR8ZqkD/rQC4Ae6uQDugW2364O84+v+yXbQ7bX2F7TwbYAdKjdsP9C0mmSzpK0S9LP6n4xIhZHxIyImNHmtgB0QVthj4jdEfFFROyX9EtJ53a3LQDd1lbYbU8Z8fD7ktbV/S6AwdDyenbbT0q6WNJk29sl/VTSxbbPkhSStkn6YQ97HHhnnnlmsX7NNdcU67fcckux3mocvuSzzz4r1j/66KNi3R51yPZLreZIL42lt+ptwYIFxXrWcfR2tQx7RMwdZfFjPegFQA9xuiyQBGEHkiDsQBKEHUiCsANJcInrGJWG11auXFlcd+rUqcV6q+Gtfv6NDtbL3pYtW1asX3fddW0/d2ZtX+IKYHwg7EAShB1IgrADSRB2IAnCDiRB2IEkmLJ5jO65557aWqtxdIxuxYoVTbeQCnt2IAnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCcfbK2WefXazPnl0/UW2ra75beeSRR4r1q6++ulg/6aSTOtp+yWGHlfcH+/fvb/u5W033PHny5GL90UcfbXvbGbFnB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEk+N74yh133FGsl65n79Qgf2/8woULi/XTTjutWJ8/f35t7YgjjmirpwOuuOKKYr3V9/mPV21/b7ztabZ/Z3uj7fW2F1bLJ9l+yfbm6vb4bjcNoHvGchj/uaR/i4i/k/RPkn5k++8l3S5pVUScIWlV9RjAgGoZ9ojYFRFvVPc/lrRR0lRJcyQtrX5tqaTyOZ0AGvWNzo23fYqk70r6vaQTI2KXNPwfgu0TatYZkjTUWZsAOjXmsNv+lqRnJf04Iv481os/ImKxpMXVcwzsB3TAeDemoTfbEzQc9Cci4rlq8W7bU6r6FEl7etMigG5ouWf38C78MUkbI+LnI0orJM2TtKi6Xd6TDvtk1qxZTbfQtn379tXWNm/eXFx37ty5xfqmTZva6umAF198sbbW6tLda6+9tlh//vnni/UlS5bU1m677bbiunv37i3WD0VjOYw/T9K/SnrH9pvVsp9oOOS/sX2jpD9K+kFvWgTQDS3DHhGvS6p7gz6zu+0A6BVOlwWSIOxAEoQdSIKwA0kQdiAJLnGtvPzyy8X6hRde2LNtf/LJJ8X6smXLivWHHnqotrZhw4a2ehoErS6ffeKJJ4r1GTNm1NbmzZvX0XMPsrYvcQUwPhB2IAnCDiRB2IEkCDuQBGEHkiDsQBKMs1dmzixfwHfvvffW1lpNmbx8eflS/wcffLBYf/fdd4v1rI488shi/eGHH66ttfp7X3bZZcX6IP9NGGcHkiPsQBKEHUiCsANJEHYgCcIOJEHYgSQYZwfGGcbZgeQIO5AEYQeSIOxAEoQdSIKwA0kQdiCJlmG3Pc3272xvtL3e9sJq+d22d9h+s/qZ3ft2AbSr5Uk1tqdImhIRb9g+RtJaSVdL+hdJf4mI/xjzxjipBui5upNqxjI/+y5Ju6r7H9veKGlqd9sD0Gvf6D277VMkfVfS76tFC2y/bftx28fXrDNke43tNR11CqAjYz433va3JL0q6d6IeM72iZLelxSS7tHwof4NLZ6Dw3igx+oO48cUdtsTJL0gaWVE/HyU+imSXoiIf2jxPIQd6LG2L4SxbUmPSdo4MujVB3cHfF/Suk6bBNA7Y/k0/nxJ/yPpHUn7q8U/kTRX0lkaPozfJumH1Yd5pedizw70WEeH8d1C2IHe43p2IDnCDiRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEi2/cLLL3pf0fyMeT66WDaJB7W1Q+5LorV3d7O3kukJfr2f/2sbtNRExo7EGCga1t0HtS6K3dvWrNw7jgSQIO5BE02Ff3PD2Swa1t0HtS6K3dvWlt0bfswPon6b37AD6hLADSTQSdtuX2/6D7S22b2+ihzq2t9l+p5qGutH56ao59PbYXjdi2STbL9neXN2OOsdeQ70NxDTehWnGG33tmp7+vO/v2W0fLmmTpFmStktaLWluRGzoayM1bG+TNCMiGj8Bw/aFkv4i6T8PTK1l+35JH0TEouo/yuMj4t8HpLe79Q2n8e5Rb3XTjF+vBl+7bk5/3o4m9uznStoSEVsj4q+Sfi1pTgN9DLyIeE3SBwctniNpaXV/qYb/sfRdTW8DISJ2RcQb1f2PJR2YZrzR167QV180Efapkv404vF2DdZ87yHpRdtrbQ813cwoTjwwzVZ1e0LD/Rys5TTe/XTQNOMD89q1M/15p5oI+2hT0wzS+N95EXG2pH+W9KPqcBVj8wtJp2l4DsBdkn7WZDPVNOPPSvpxRPy5yV5GGqWvvrxuTYR9u6RpIx5/W9LOBvoYVUTsrG73SPqtht92DJLdB2bQrW73NNzPlyJid0R8ERH7Jf1SDb521TTjz0p6IiKeqxY3/tqN1le/Xrcmwr5a0hm2v2P7CEnXSlrRQB9fY/vo6oMT2T5a0vc0eFNRr5A0r7o/T9LyBnv5ikGZxrtumnE1/No1Pv15RPT9R9JsDX8i/66kO5vooaavUyW9Vf2sb7o3SU9q+LDuMw0fEd0o6W8lrZK0ubqdNEC9/ZeGp/Z+W8PBmtJQb+dr+K3h25LerH5mN/3aFfrqy+vG6bJAEpxBByRB2IEkCDuQBGEHkiDsQBKEHUiCsANJ/D/j+Gt6lKo/gwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Label: ', training_label[0])\n",
    "plt.imshow(training_img_vectors[0].reshape(28,28),cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the Data (Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Label: ', test_label[9])\n",
    "plt.imshow(test_img_vectors[9].reshape(28,28),cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN Model\n",
    "\n",
    "- The implementation has a complexity of $O(nd+kn)$ (since d<<n and k<<n, we have $O(nd+kn)=O(n)$), where d is the data dimension and n is the number of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_dist(data_0, data_1): \n",
    "    return np.linalg.norm(data_0 - data_1, ord=2)\n",
    "\n",
    "\n",
    "class kNN_model:\n",
    "    def __init__(self, n_neighbors, dist=euclidean_dist):\n",
    "        self.dist_func = dist\n",
    "        self.k = n_neighbors\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def predict(self, data_x):\n",
    "        prediction = []\n",
    "        for data_point in data_x:\n",
    "            prediction.append(self.predict_each(data_point))\n",
    "        return prediction\n",
    "    \n",
    "    def predict_each(self, data_x):\n",
    "        neighbor_idx, _ = self.k_neighbors(data_x)\n",
    "\n",
    "        # use the selected neighbors to get the prediction\n",
    "        votes = list()\n",
    "        for idx in neighbor_idx:\n",
    "            votes.append(self.y[idx])\n",
    "        vote_counter = Counter(votes)\n",
    "        # return the most frequent\n",
    "        return vote_counter.most_common()[0][0]\n",
    "    \n",
    "    def k_neighbors(self, data_x):\n",
    "        n_data = self.X.shape[0]\n",
    "        is_selected = np.zeros(shape=(n_data,), dtype=np.int8)\n",
    "        neighbor_idx = list()\n",
    "        \n",
    "        # calculate the distance\n",
    "        distance = np.zeros(shape=(n_data,))\n",
    "        for x_i, x in enumerate(self.X):\n",
    "            distance[x_i] = self.dist_func(data_x, x)\n",
    "\n",
    "        for _ in range(0, self.k):\n",
    "            current_min = None\n",
    "            current_min_index = None\n",
    "            \n",
    "            for x_i, x in enumerate(self.X):\n",
    "                if is_selected[x_i] == 1:\n",
    "                    continue\n",
    "                \n",
    "                dist_to_neighbor = distance[x_i]\n",
    "                if current_min is None or current_min > dist_to_neighbor:\n",
    "                    current_min = dist_to_neighbor\n",
    "                    current_min_index = x_i\n",
    "                \n",
    "            # select the current minimum\n",
    "            is_selected[current_min_index] = 1\n",
    "            neighbor_idx.append(current_min_index)\n",
    "        return neighbor_idx, distance[neighbor_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 1, test data: 999/999, prediction: 5, true prediction: 8, current accuray: 0.944000\n",
      "k:  1 , accuracy:  0.944\n",
      "k: 3, test data: 999/999, prediction: 5, true prediction: 8, current accuray: 0.945000\n",
      "k:  3 , accuracy:  0.945\n",
      "k: 5, test data: 768/999, prediction: 7, true prediction: 7, current accuray: 0.946684"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-246-295b69bef4c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0maccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_k\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0maccuracy_knn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkNN_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_img_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_img_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-246-295b69bef4c1>\u001b[0m in \u001b[0;36mrun_evaluation\u001b[0;34m(model_to_use, training_X, training_y, test_X, test_y)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtest_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mtrue_prediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtrue_prediction\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-245-02ba12dd6aba>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data_x)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdata_point\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_x\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_each\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_point\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-245-02ba12dd6aba>\u001b[0m in \u001b[0;36mpredict_each\u001b[0;34m(self, data_x)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_each\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mneighbor_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_neighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# use the selected neighbors to get the prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-245-02ba12dd6aba>\u001b[0m in \u001b[0;36mk_neighbors\u001b[0;34m(self, data_x)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mx_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mis_selected\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_i\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def run_evaluation(model_to_use, training_X, training_y, test_X, test_y):\n",
    "    k_list = [1, 3, 5, 10, 20, 30, 40, 50, 60]\n",
    "    accuracy = []\n",
    "    n_test = float(test_y.shape[0])\n",
    "    \n",
    "    for k in k_list:\n",
    "        model = model_to_use(n_neighbors=k)\n",
    "        model.fit(training_X, training_y)\n",
    "        \n",
    "        n_correct = 0\n",
    "        for test_idx in range(0, int(n_test)):\n",
    "            \n",
    "            prediction = model.predict([test_X[test_idx]])[0]\n",
    "            true_prediction = test_y[test_idx]\n",
    "            if prediction == true_prediction:\n",
    "                n_correct += 1\n",
    "            \n",
    "            log_str = '\\rk: %d, test data: %d/%d, prediction: %d, true prediction: %d, current accuray: %f' % (k, test_idx, n_test-1, prediction, true_prediction, float(n_correct/(test_idx+1)))\n",
    "            sys.stdout.write(log_str)\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "        accuracy_k = n_correct/n_test\n",
    "        print('\\nk: ', k, ', accuracy: ', accuracy_k)\n",
    "        accuracy.append(accuracy_k)\n",
    "        \n",
    "        return accuracy\n",
    "\n",
    "accuracy_knn = run_evaluation(kNN_model, training_img_vectors, training_label, test_img_vectors, test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare to the kNN in skkearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk:  2942.7641767562686\n",
      "float64\n",
      "float64\n",
      "a: 2942.7641767562686\n",
      "b: 2942.7641767562686\n",
      "c: 2942.7641767562686\n",
      "(784,)\n",
      "2\n",
      "(784,)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "accuracy_knn_sklearn = run_evaluation(KNeighborsClassifier, training_img_vectors, training_label, test_img_vectors, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
